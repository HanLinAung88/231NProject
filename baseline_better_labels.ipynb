{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:86: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc val\n",
      "AUROC val 0.8814483461088521\n",
      "AUROC all [0.8485039370078741, 0.8375, 0.9291666666666667, 0.8640819964349375, 0.9279891304347826]\n",
      "Loss:0.7051451802253723\n",
      "epoc val\n",
      "AUROC val 0.8814483461088521\n",
      "AUROC all [0.8485039370078741, 0.8375, 0.9291666666666667, 0.8640819964349375, 0.9279891304347826]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-278ac0d74405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0mlaunchTimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'm-0.897_starter37050_0.897.pth.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAIN_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAL_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnArchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnIsTrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransResize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaunchTimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-278ac0d74405>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint, classes)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mlossTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochTrain\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mlossVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosstensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochVal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-278ac0d74405>\u001b[0m in \u001b[0;36mepochTrain\u001b[0;34m(model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter, classes)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mlossvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'better_labels_logs/train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatchID\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "writer = SummaryWriter('./better_labels_logs')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Read images and corresponding labels.\n",
    "\"\"\"\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    \n",
    "    def convert_to_ones(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 1.0)\n",
    "    \n",
    "    def convert_to_zeros(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 0.0)\n",
    "        \n",
    "    def convert_to_multi(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 2.0)\n",
    "\n",
    "    def __init__(self, data_dir, image_list_file, diseases=['Atelectasis', 'Consolidation', 'Edema','Cardiomegaly', 'Pleural Effusion'], side='Frontal', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        chex_df = pd.read_csv(image_list_file)\n",
    "        chex_df = chex_df.fillna(0.0)\n",
    "        chex_df = chex_df.loc[chex_df['Frontal/Lateral'] == side]\n",
    "        self.convert_to_ones(chex_df, 'Atelectasis')\n",
    "        self.convert_to_multi(chex_df, 'Consolidation')\n",
    "        self.convert_to_ones(chex_df, 'Edema')\n",
    "        self.convert_to_multi(chex_df, 'Cardiomegaly')\n",
    "        self.convert_to_multi(chex_df, 'Pleural Effusion')\n",
    "\n",
    "#         chex_df_diseases = chex_df[diseases]\n",
    "                         \n",
    "#         if 'train' in image_list_file:\n",
    "#             chex_df = chex_df\n",
    "#         if len(diseases) == 1:\n",
    "#             chex_df = chex_df.loc[chex_df['Pleural Effusion'] != -1] #U-Ignore\n",
    "#         print(chex_df)\n",
    "        labels = chex_df.as_matrix(columns=diseases)\n",
    "        labels = list(labels)\n",
    "\n",
    "        image_names = chex_df.as_matrix(columns=['Path']).flatten()\n",
    "        image_names = [os.path.join(data_dir, im_name) for im_name in image_names]\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class ChexnetTrainer():\n",
    "\n",
    "    #---- Train the densenet network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    #--- classes - is the number of classes to predict (Note =/= final layer of Dense Net) -- Saj\n",
    "    \n",
    "    \n",
    "    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint,classes):\n",
    "        #------------------  Special Loss \n",
    "        # Takes in Logits, except 0,1,2 --> logits => sigmoid\n",
    "        # returns multi label loss\n",
    "        def lossCriterion(varOutput,varTarget):\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "            L1 = BCEloss(varOutput[:,0],varTarget[:,0])\n",
    "            varTarget = varTarget.long()\n",
    "            L2 = CEloss(varOutput[:,1:4],varTarget[:,1])\n",
    "            \n",
    "            varTarget = varTarget.float()\n",
    "            L3 = BCEloss(varOutput[:,4],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,5:8],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,8:11],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            lossvalue = (L1 + L2 + L3 + L4 + L5)/5\n",
    "            \n",
    "            return lossvalue\n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'RES-NET-18': model = ResNet18(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "       \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\n",
    "        normalize = transforms.Normalize([0.50616586, 0.50616586, 0.50616586], [0.2879059, 0.2879059, 0.2879059]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)    \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "        #-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "                    \n",
    "        datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, transform=transformSequence)              \n",
    "        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "        datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, transform=transformSequence)\n",
    "        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=0, pin_memory=False)\n",
    "        \n",
    "        \n",
    "        \t#---- Load checkpoint \n",
    "        if checkpoint != None:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            #optimizer.load_state_dict(modelCheckpoint['optimizer']) ##maybe don't need this\n",
    "            counter = modelCheckpoint['counter']\n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "\n",
    "        #-------------------- SETTINGS: LOSS\n",
    "        loss = lossCriterion\n",
    "       \n",
    "        counter = 0\n",
    "        \n",
    "        #---- TRAIN THE NETWORK\n",
    "        lossMIN = 100000\n",
    "        \n",
    "        for epochID in range (0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "                         \n",
    "            lossTrain, counter = ChexnetTrainer.epochTrain (model, dataLoaderTrain, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter,classes)\n",
    "            lossVal, losstensor, __ = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter,classes)\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "\n",
    "            scheduler.step(losstensor.item())\n",
    "            writer.add_scalar('better_labels_logs/train_loss_epoch', lossTrain, epochID)\n",
    "            writer.add_scalar('better_labels_logs/val_loss_epoch', lossVal, epochID)\n",
    "            if lossVal < lossMIN:\n",
    "\n",
    "                lossMIN = lossVal    \n",
    "                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, './better_labels_forward/m-' + launchTimestamp + '.pth.tar')\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            else:\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "                     \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain (model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes):\n",
    "        \n",
    "        model.train()\n",
    "        lossTrain = 0\n",
    "        lossTrainNorm = 0\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for batchID, (input, target) in enumerate (dataLoader):\n",
    "\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input)\n",
    "            varTarget = torch.autograd.Variable(target)         \n",
    "            varOutput = model(varInput)\n",
    "\n",
    "\n",
    "            varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "            varOutput[:,4] = torch.sigmoid(varOutput[:,4])\n",
    "\n",
    "            lossvalue = loss(varOutput,varTarget)\n",
    "\n",
    "            avg_loss = avg_loss * (batchID)/(batchID+1) + lossvalue * 1.0/(batchID+ 1)\n",
    "            lossTrain += lossvalue\n",
    "            lossTrainNorm += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('better_labels_logs/train_loss', avg_loss, counter)\n",
    "            if batchID % 200 == 0:\n",
    "                ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes)\n",
    "                print('Loss:' + str(avg_loss.item()))\n",
    "            if batchID % 2400 == 0:\n",
    "                __, __, aurocMean = ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes)\n",
    "                torch.save({'counter' : counter, 'state_dict': model.state_dict(), 'valAUROC' : aurocMean , 'optimizer' : optimizer.state_dict()}, './better_labels_forward/m-' + str(counter) + '_' + str(round(aurocMean, 3)) + '.pth.tar')\n",
    "\n",
    "                \n",
    "#             print(counter)\n",
    "            counter += 1\n",
    "\n",
    "        outLoss = lossTrain/lossTrainNorm\n",
    "        return outLoss, counter\n",
    "\n",
    "                        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "        \n",
    "    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss, counter,classes):\n",
    "        \n",
    "        print('epoc val')\n",
    "        model.eval()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        losstensorMean = 0\n",
    "\n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(dataLoader):\n",
    "                #Val code\n",
    "                target = target.cuda()\n",
    "                varInput = torch.autograd.Variable(input.cuda())\n",
    "                varTarget = torch.autograd.Variable(target)\n",
    "                varOutput = model(varInput)\n",
    "\n",
    "                varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "                \n",
    "                varOutput[:,4] = torch.sigmoid(varOutput[:,4])            \n",
    "\n",
    "\n",
    "                ### VAL Preds for AUROC\n",
    "                bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "                bPRED[:,0] = varOutput[:,0]\n",
    "                bPRED[:,2] = varOutput[:,4]\n",
    "                \n",
    "                soft_a = torch.nn.functional.softmax(varOutput[:,1:4], dim=-1).data\n",
    "\n",
    "                a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "                bPRED[:, 1] = a1/(a0+a1)\n",
    "                soft_b = torch.nn.functional.softmax(varOutput[:,5:8], dim=-1).data\n",
    "                b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "                bPRED[:, 3] = b1/(b0+b1)\n",
    "                \n",
    "                soft_c = torch.nn.functional.softmax(varOutput[:,8:11], dim=-1).data\n",
    "                c0, c1, c2 = soft_c[:, 0], soft_c[:, 1], soft_c[:, 2]\n",
    "                bPRED[:, 4] = c1/(c0+c1)\n",
    "\n",
    "                outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "                outGT = torch.cat((outGT, target), 0)\n",
    "\n",
    "\n",
    "                losstensor = loss(varOutput,varTarget)\n",
    "\n",
    "                losstensorMean += losstensor\n",
    "                lossVal += losstensor.item()\n",
    "                lossValNorm += 1\n",
    "                ##block comment was here\n",
    "\n",
    "            outLoss = lossVal / lossValNorm\n",
    "            losstensorMean = losstensorMean / lossValNorm\n",
    "\n",
    "            aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, classes)\n",
    "            aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "            print(\"AUROC val\", aurocMean)\n",
    "            print(\"AUROC all\", aurocIndividual)\n",
    "            writer.add_scalar('better_labels_logs/val_auroc', aurocMean, counter)\n",
    "\n",
    "        return outLoss, losstensorMean, aurocMean            \n",
    "#             outGT = torch.cat((outGT, target), 0)\n",
    "# outPred = empty variable\n",
    "\n",
    "\n",
    "##varMean to varOutput\n",
    "#             outPRED = torch.zeros(out.shape[0], 5).cuda()\n",
    "#             outPRED[:,0] = outMean[:,0]\n",
    "#             outPRED[:,1] = outMean[:,1]\n",
    "#             outPRED[:,2] = outMean[:,2]\n",
    "#             outPRED[:,3] = torch.max(outMean[:,3:6],1)[0]\n",
    "#             outPRED[:,4] = torch.max(outMean[:,6:9],1)[0]\n",
    "\n",
    "# #             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "############            \n",
    "#             outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "#             bs, c, h, w = input.size()\n",
    "\n",
    "#             varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "            \n",
    "#             out = model(varInput)\n",
    "#             outMean = out.view(bs, -1)\n",
    "    \n",
    "#             outPRED = torch.zeros(out.shape[0], 5).cuda()\n",
    "#             outPRED[:,0] = outMean[:,0]\n",
    "#             outPRED[:,1] = outMean[:,1]\n",
    "#             outPRED[:,2] = outMean[:,2]\n",
    "#             outPRED[:,3] = torch.max(outMean[:,3:6],1)[0]\n",
    "#             outPRED[:,4] = torch.max(outMean[:,6:9],1)[0]\n",
    "            \n",
    "            \n",
    "# #             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "            \n",
    "#             varOutput = outPRED\n",
    "#             varTarget = outGT\n",
    "            \n",
    "# #             losstensor = loss(varOutput, varTarget)\n",
    "\n",
    "#             CEloss =  torch.nn.CrossEntropyLoss()\n",
    "#             BCEloss = torch.nn.BCELoss()\n",
    "\n",
    "# #             varTarget = varTarget.type(torch.long)\n",
    "#             L1 = BCEloss(varOutput[:,:1],varTarget[:,0]) \n",
    "#             L2 = BCEloss(varOutput[:,1:2],varTarget[:,1])\n",
    "#             L3 = BCEloss(varOutput[:,2:3],varTarget[:,2])\n",
    "#             varTarget = varTarget.long()\n",
    "#             L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "#             L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "#             losstensor = L1 + L2 + L3 + L4 + L5\n",
    "#             losstensor /= 5\n",
    "\n",
    "\n",
    "#             losstensorMean += losstensor\n",
    "#             lossVal += losstensor.item()\n",
    "#             lossValNorm += 1\n",
    "            \n",
    "\n",
    "               \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            \n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------------  \n",
    "    \n",
    "    #---- Test the trained network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n",
    "        \n",
    "        \n",
    "        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda() \n",
    "        \n",
    "        modelCheckpoint = torch.load(pathModel)\n",
    "        model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS\n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.TenCrop(transCrop))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=0, shuffle=False, pin_memory=False)\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoaderTest):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "            bs, n_crops, c, h, w = input.size()\n",
    "            \n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda())\n",
    "            \n",
    "            out = model(varInput)\n",
    "            outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "            outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "        return\n",
    "#-------------------------------------------------------------------------------- \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'DENSE-NET-121'\n",
    "\n",
    "nnClassCount = 11\n",
    "classes = 5\n",
    "\n",
    "trBatchSize = 32\n",
    "trMaxEpoch = 50\n",
    "transResize = (300, 300)\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = 'm-0.897_starter37050_0.897.pth.tar'\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint,classes)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
