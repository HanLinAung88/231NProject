{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121, DenseNet121_Sigmoid\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.chexnet.DatasetGenerator import DatasetGenerator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read images and corresponding labels.\n",
    "\"\"\"\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    \n",
    "    def convert_to_ones(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 1.0)\n",
    "    \n",
    "    def convert_to_zeros(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 0.0)\n",
    "        \n",
    "    def convert_to_multi(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 2.0)\n",
    "\n",
    "    def __init__(self, data_dir, image_list_file, diseases=['Atelectasis', 'Consolidation', 'Edema','Cardiomegaly', 'Pleural Effusion'], side='Frontal', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        chex_df = pd.read_csv(image_list_file)\n",
    "        chex_df = chex_df.fillna(0.0)\n",
    "        chex_df = chex_df.loc[chex_df['Frontal/Lateral'] == side]\n",
    "        self.convert_to_ones(chex_df, 'Atelectasis')\n",
    "        self.convert_to_ones(chex_df, 'Consolidation')\n",
    "        self.convert_to_ones(chex_df, 'Edema')\n",
    "        self.convert_to_ones(chex_df, 'Cardiomegaly')\n",
    "        self.convert_to_ones(chex_df, 'Pleural Effusion')\n",
    "\n",
    "#         chex_df_diseases = chex_df[diseases]\n",
    "                         \n",
    "#         if 'train' in image_list_file:\n",
    "#             chex_df = chex_df\n",
    "#         if len(diseases) == 1:\n",
    "#             chex_df = chex_df.loc[chex_df['Pleural Effusion'] != -1] #U-Ignore\n",
    "#         print(chex_df)\n",
    "        labels = chex_df.as_matrix(columns=diseases)\n",
    "        labels = list(labels)\n",
    "\n",
    "        image_names = chex_df.as_matrix(columns=['Path']).flatten()\n",
    "        image_names = [os.path.join(data_dir, im_name) for im_name in image_names]\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "transCrop = 224\n",
    "\n",
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "transformList = []\n",
    "transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "transformList.append(transforms.RandomHorizontalFlip())\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)\n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST,\n",
    "                                diseases =['Pleural Effusion'],\n",
    "                                transform=transformSequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChexnetTrainer ():\n",
    "\n",
    "    #---- Train the densenet network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    \n",
    "    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint):\n",
    "\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'RES-NET-18': model = ResNet18(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "       \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "        #-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "                    \n",
    "        datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, transform=transformSequence)\n",
    "        #datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, diseases=['Pleural Effusion'], transform=transformSequence)\n",
    "              \n",
    "        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "        #dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "        transformList = []\n",
    "        \n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        \n",
    "        \n",
    "#         transformList.append(transforms.Resize(transResize))\n",
    "#         transformList.append(transforms.TenCrop(transCrop))\n",
    "#        transformList.append(normalize)  \n",
    "#         transformList.append(transforms.ToTensor())\n",
    "#         transformList.append(normalize)\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, transform=transformSequence)\n",
    "        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "                \n",
    "        #-------------------- SETTINGS: LOSS\n",
    "        loss = torch.nn.BCELoss(size_average = True)\n",
    "        \n",
    "        #---- Load checkpoint \n",
    "        if checkpoint != None:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "\n",
    "        \n",
    "        #---- TRAIN THE NETWORK\n",
    "        counter = 0\n",
    "        lossMIN = 100000\n",
    "        \n",
    "        for epochID in range (0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "                         \n",
    "            lossTrain, counter = ChexnetTrainer.epochTrain (model, dataLoaderTrain, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter)\n",
    "            lossVal, losstensor = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter)\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "\n",
    "            scheduler.step(losstensor.item())\n",
    "            writer.add_scalar('logs/train_loss_epoch', lossTrain, epochID)\n",
    "            writer.add_scalar('logs/val_loss_epoch', lossVal, epochID)\n",
    "            if lossVal < lossMIN:\n",
    "\n",
    "                lossMIN = lossVal    \n",
    "                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'm-' + launchTimestamp + '.pth.tar')\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            else:\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "                     \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain (model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter):\n",
    "        \n",
    "        model.train()\n",
    "        lossTrain = 0\n",
    "        lossTrainNorm = 0\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "        for batchID, (input, target) in enumerate (dataLoader):\n",
    "\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input)\n",
    "            varTarget = torch.autograd.Variable(target)         \n",
    "            varOutput = model(varInput)\n",
    "            \n",
    "#             lossvalue = loss(varOutput, varTarget)\n",
    "\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "\n",
    "#             varTarget = varTarget.type(torch.long)\n",
    "            L1 = BCEloss(varOutput[:,:1],varTarget[:,0]) \n",
    "            L2 = BCEloss(varOutput[:,1:2],varTarget[:,1])\n",
    "            L3 = BCEloss(varOutput[:,2:3],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            lossvalue = L1 + L2 + L3 + L4 + L5\n",
    "            lossvalue /= 5\n",
    "\n",
    "            print(lossvalue)\n",
    "            avg_loss = avg_loss * (batchID)/(batchID+1) + lossvalue * 1.0/(batchID+ 1)\n",
    "            lossTrain += lossvalue\n",
    "            lossTrainNorm += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('logs/train_loss', avg_loss, counter)\n",
    "            if batchID % 1000 == 0:\n",
    "                ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter)\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        outLoss = lossTrain/lossTrainNorm\n",
    "        return outLoss, counter\n",
    "\n",
    "                        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "        \n",
    "    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss, counter):\n",
    "        \n",
    "        model.eval ()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        losstensorMean = 0\n",
    "        \n",
    "        \n",
    "        ###Old code-- didn't handle 5d shapes with crops. We should think about whether we want to crop on val\n",
    "#         outGT = torch.FloatTensor().cuda()\n",
    "#         outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        \n",
    "#         for i, (input, target) in enumerate (dataLoader):\n",
    "#             target = target.cuda()\n",
    "#             outGT = torch.cat((outGT, target), 0)\n",
    "        \n",
    "#             bs, n_crops, c, h, w = input.size()\n",
    "#             print(\"Val\", input.size())\n",
    "#             varInput = torch.autograd.Variable(input, volatile=True)\n",
    "#             varTarget = torch.autograd.Variable(target, volatile=True)    \n",
    "#             varOutput = model(varInput)\n",
    "            \n",
    "#             outMean = varOutput.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "#             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        ### Validation computes mean prediction over 10 crops, NOT like in training. \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoader):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "#             bs, n_crops, c, h, w = input.size()\n",
    "            bs, c, h, w = input.size()\n",
    "\n",
    "\n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "            \n",
    "            out = model(varInput)\n",
    "#             outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            outMean = out.view(bs, -1)\n",
    "    \n",
    "            outPRED = torch.zeros(out.shape[0], 5).cuda()\n",
    "            outPRED[:,0] = outMean[:,0]\n",
    "            outPRED[:,1] = outMean[:,1]\n",
    "            outPRED[:,2] = outMean[:,2]\n",
    "            outPRED[:,3] = torch.max(outMean[:,3:6],1)[0]\n",
    "            outPRED[:,4] = torch.max(outMean[:,6:9],1)[0]\n",
    "            \n",
    "            \n",
    "#             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "            \n",
    "            varOutput = outPRED\n",
    "            varTarget = outGT\n",
    "            \n",
    "#             losstensor = loss(varOutput, varTarget)\n",
    "\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "\n",
    "#             varTarget = varTarget.type(torch.long)\n",
    "            L1 = BCEloss(varOutput[:,:1],varTarget[:,0]) \n",
    "            L2 = BCEloss(varOutput[:,1:2],varTarget[:,1])\n",
    "            L3 = BCEloss(varOutput[:,2:3],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            losstensor = L1 + L2 + L3 + L4 + L5\n",
    "            losstensor /= 5\n",
    "\n",
    "\n",
    "            losstensorMean += losstensor\n",
    "            lossVal += losstensor.item()\n",
    "            lossValNorm += 1\n",
    "            \n",
    "        outLoss = lossVal / lossValNorm\n",
    "        losstensorMean = losstensorMean / lossValNorm\n",
    "        \n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, classCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        #print(\"AUROC val\", aurocMean)\n",
    "        writer.add_scalar('logs/val_auroc', aurocMean, counter)\n",
    "        \n",
    "        return outLoss, losstensorMean\n",
    "               \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            \n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------------  \n",
    "    \n",
    "    #---- Test the trained network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n",
    "        \n",
    "        \n",
    "        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda() \n",
    "        \n",
    "        modelCheckpoint = torch.load(pathModel)\n",
    "        model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS\n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.TenCrop(transCrop))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=4, shuffle=False, pin_memory=True)\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoaderTest):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "            bs, n_crops, c, h, w = input.size()\n",
    "            \n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "            \n",
    "            out = model(varInput)\n",
    "            outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "            outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "        return\n",
    "#-------------------------------------------------------------------------------- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST,\n",
    "                                diseases =['Pleural Effusion'],\n",
    "                                transform=transformSequence)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'RES-NET-18'\n",
    "nnClassCount = 1\n",
    "trBatchSize = 10\n",
    "trMaxEpoch = 50\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = None\n",
    "\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "# valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "#                                 image_list_file=VAL_IMAGE_LIST,\n",
    "#                                 diseases =['Pleural Effusion'],\n",
    "#                                 transform=transformSequence)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'DENSE-NET-121'\n",
    "nnClassCount = 1\n",
    "trBatchSize = 4\n",
    "trMaxEpoch = 50\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "launchTimestamp = 'dense'\n",
    "checkpoint = None\n",
    "\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8192, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:217: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: non-empty vector or matrix expected at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4bd83ffdca9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAIN_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAL_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnArchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnIsTrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransResize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaunchTimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-acca78db4df7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtimestampSTART\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampDate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimestampTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mlossTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochTrain\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mlossVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosstensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochVal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-acca78db4df7>\u001b[0m in \u001b[0;36mepochTrain\u001b[0;34m(model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatchID\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochMax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-acca78db4df7>\u001b[0m in \u001b[0;36mepochVal\u001b[0;34m(model, dataLoader, optimizer, scheduler, epochMax, classCount, loss, counter)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mvarTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mL4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCEloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvarTarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mL5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCEloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvarTarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: non-empty vector or matrix expected at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THCUNN/generic/ClassNLLCriterion.cu:31"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'DENSE-NET-121'\n",
    "nnClassCount = 9\n",
    "trBatchSize = 6\n",
    "trMaxEpoch = 50\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = None\n",
    "\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here is the working code for our base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChexnetTrainer ():\n",
    "\n",
    "    #---- Train the densenet network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    \n",
    "    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint):\n",
    "\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n",
    "        if nnArchitecture == 'DENSE-NET-121-Sigmoid': model = DenseNet121_Sigmoid(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained)#.cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained)#.cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained)#.cuda()\n",
    "        elif nnArchitecture == 'RES-NET-18': model = ResNet18(nnClassCount, nnIsTrained)#.cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model)#.cuda()\n",
    "       \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "        #-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "                    \n",
    "        datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, transform=transformSequence)\n",
    "        #datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, diseases=['Pleural Effusion'], transform=transformSequence)\n",
    "              \n",
    "        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "        #dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "        transformList = []\n",
    "        \n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        \n",
    "        \n",
    "#         transformList.append(transforms.Resize(transResize))\n",
    "#         transformList.append(transforms.TenCrop(transCrop))\n",
    "#        transformList.append(normalize)  \n",
    "#         transformList.append(transforms.ToTensor())\n",
    "#         transformList.append(normalize)\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, transform=transformSequence)\n",
    "        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "                \n",
    "        #-------------------- SETTINGS: LOSS\n",
    "        loss = torch.nn.BCELoss(size_average = True)\n",
    "        \n",
    "        #---- Load checkpoint \n",
    "        if checkpoint != None:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "\n",
    "        \n",
    "        #---- TRAIN THE NETWORK\n",
    "        counter = 0\n",
    "        lossMIN = 100000\n",
    "        \n",
    "        for epochID in range (0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "                         \n",
    "            lossTrain, counter = ChexnetTrainer.epochTrain (model, dataLoaderTrain, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter)\n",
    "            lossVal, losstensor = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter)\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "\n",
    "            scheduler.step(losstensor.item())\n",
    "            writer.add_scalar('logs/train_loss_epoch', lossTrain, epochID)\n",
    "            writer.add_scalar('logs/val_loss_epoch', lossVal, epochID)\n",
    "            if lossVal < lossMIN:\n",
    "\n",
    "                lossMIN = lossVal    \n",
    "                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'm-' + launchTimestamp + '.pth.tar')\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            else:\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "                     \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain (model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter):\n",
    "        \n",
    "        model.train()\n",
    "        lossTrain = 0\n",
    "        lossTrainNorm = 0\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "        for batchID, (input, target) in enumerate (dataLoader):\n",
    "            \n",
    "            target = target#.cuda()\n",
    "            varInput = torch.autograd.Variable(input)\n",
    "            varTarget = torch.autograd.Variable(target)         \n",
    "            varOutput = model(varInput)\n",
    "            \n",
    "#             lossvalue = loss(varOutput, varTarget)\n",
    "\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "            varOutput = varOutput.cpu()\n",
    "            print(varOutput.shape)\n",
    "#             varTarget = varTarget.type(torch.long)\n",
    "            L1 = BCEloss(varOutput[:,:1],varTarget[:,0]) \n",
    "            L2 = BCEloss(varOutput[:,1:2],varTarget[:,1])\n",
    "            L3 = BCEloss(varOutput[:,2:3],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            lossvalue = L1 + L2 + L3 + L4 + L5\n",
    "            lossvalue /= 5\n",
    "\n",
    "            print(lossvalue)\n",
    "            avg_loss = avg_loss * (batchID)/(batchID+1) + lossvalue * 1.0/(batchID+ 1)\n",
    "            lossTrain += lossvalue\n",
    "            lossTrainNorm += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('logs/train_loss', avg_loss, counter)\n",
    "            if batchID % 1000 == 0:\n",
    "                ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter)\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        outLoss = lossTrain/lossTrainNorm\n",
    "        return outLoss, counter\n",
    "\n",
    "                        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "        \n",
    "    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss, counter):\n",
    "        \n",
    "        model.eval ()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        losstensorMean = 0\n",
    "        \n",
    "        \n",
    "        ###Old code-- didn't handle 5d shapes with crops. We should think about whether we want to crop on val\n",
    "#         outGT = torch.FloatTensor().cuda()\n",
    "#         outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        \n",
    "#         for i, (input, target) in enumerate (dataLoader):\n",
    "#             target = target.cuda()\n",
    "#             outGT = torch.cat((outGT, target), 0)\n",
    "        \n",
    "#             bs, n_crops, c, h, w = input.size()\n",
    "#             print(\"Val\", input.size())\n",
    "#             varInput = torch.autograd.Variable(input, volatile=True)\n",
    "#             varTarget = torch.autograd.Variable(target, volatile=True)    \n",
    "#             varOutput = model(varInput)\n",
    "            \n",
    "#             outMean = varOutput.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "#             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        ### Validation computes mean prediction over 10 crops, NOT like in training. \n",
    "        outGT = torch.FloatTensor()#.cuda()\n",
    "        outPRED = torch.FloatTensor()#.cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoader):\n",
    "            \n",
    "            target = target#.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "#             bs, n_crops, c, h, w = input.size()\n",
    "            bs, c, h, w = input.size()\n",
    "\n",
    "\n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w), volatile=True) # .cuda() for input\n",
    "            \n",
    "            out = model(varInput)\n",
    "#             outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            outMean = out.view(bs, -1)\n",
    "            print(outMean.type)\n",
    "            outPRED = torch.zeros(out.shape[0], 5)#.cuda()\n",
    "            outPRED[:,0] = outMean[:,0]\n",
    "            outPRED[:,1] = outMean[:,1]\n",
    "            outPRED[:,2] = outMean[:,2]\n",
    "            outPRED[:,3] = torch.max(outMean[:,3:6],1)[0]\n",
    "            outPRED[:,4] = torch.max(outMean[:,6:9],1)[0]\n",
    "            \n",
    "            \n",
    "#             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "            \n",
    "            varOutput = outPRED\n",
    "            varTarget = outGT\n",
    "            \n",
    "#             losstensor = loss(varOutput, varTarget)\n",
    "\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "\n",
    "#             varTarget = varTarget.type(torch.long)\n",
    "            L1 = BCEloss(varOutput[:,:1],varTarget[:,0]) \n",
    "            L2 = BCEloss(varOutput[:,1:2],varTarget[:,1])\n",
    "            L3 = BCEloss(varOutput[:,2:3],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            losstensor = L1 + L2 + L3 + L4 + L5\n",
    "            losstensor /= 5\n",
    "\n",
    "\n",
    "            losstensorMean += losstensor\n",
    "            lossVal += losstensor.item()\n",
    "            lossValNorm += 1\n",
    "            \n",
    "        outLoss = lossVal / lossValNorm\n",
    "        losstensorMean = losstensorMean / lossValNorm\n",
    "        \n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, classCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        #print(\"AUROC val\", aurocMean)\n",
    "        writer.add_scalar('logs/val_auroc', aurocMean, counter)\n",
    "        \n",
    "        return outLoss, losstensorMean\n",
    "               \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            \n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------------  \n",
    "    \n",
    "    #---- Test the trained network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n",
    "        \n",
    "        \n",
    "        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n",
    "        if nnArchitecture == 'DENSE-NET-121-Sigmoid': model = DenseNet121_Sigmoid(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda() \n",
    "        \n",
    "        modelCheckpoint = torch.load(pathModel)\n",
    "        model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS\n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.TenCrop(transCrop))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=4, shuffle=False, pin_memory=True)\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoaderTest):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "            bs, n_crops, c, h, w = input.size()\n",
    "            \n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "            \n",
    "            out = model(varInput)\n",
    "            outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "            outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "        return\n",
    "#-------------------------------------------------------------------------------- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf19177defc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mChexnetTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRAIN_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAL_IMAGE_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnArchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnIsTrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrBatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrMaxEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransResize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransCrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaunchTimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4ed39f0ab26d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnnArchitecture\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RES-NET-18'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnIsTrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'DENSE-NET-121'\n",
    "nnClassCount = 9\n",
    "trBatchSize = 6\n",
    "trMaxEpoch = 50\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = None\n",
    "\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original baseline without our cool loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChexnetTrainer ():\n",
    "\n",
    "    #---- Train the densenet network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint):\n",
    "\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n",
    "        if nnArchitecture == 'DENSE-NET-121-Sigmoid': model = DenseNet121_Sigmoid(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model)#.cuda()\n",
    "       \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "        #-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "                    \n",
    "        datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, transform=transformSequence)\n",
    "        #datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, diseases=['Pleural Effusion'], transform=transformSequence)\n",
    "              \n",
    "        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "        #dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=24, pin_memory=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "        transformList = []\n",
    "        \n",
    "        transformList.append(transforms.RandomResizedCrop(transCrop))\n",
    "        transformList.append(transforms.RandomHorizontalFlip())\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)      \n",
    "        \n",
    "        \n",
    "#         transformList.append(transforms.Resize(transResize))\n",
    "#         transformList.append(transforms.TenCrop(transCrop))\n",
    "#        transformList.append(normalize)  \n",
    "#         transformList.append(transforms.ToTensor())\n",
    "#         transformList.append(normalize)\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "      \n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, transform=transformSequence)\n",
    "        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "                \n",
    "        #-------------------- SETTINGS: LOSS\n",
    "        loss = torch.nn.BCELoss(size_average = True)\n",
    "        \n",
    "        #---- Load checkpoint \n",
    "        if checkpoint != None:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "\n",
    "        \n",
    "        #---- TRAIN THE NETWORK\n",
    "        \n",
    "        lossMIN = 100000\n",
    "        \n",
    "        for epochID in range (0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "                         \n",
    "            ChexnetTrainer.epochTrain (model, dataLoaderTrain, optimizer, scheduler, trMaxEpoch, nnClassCount, loss)\n",
    "            lossVal, losstensor = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss)\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "            \n",
    "            scheduler.step(losstensor.data[0])\n",
    "            \n",
    "            if lossVal < lossMIN:\n",
    "                lossMIN = lossVal    \n",
    "                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'm-' + launchTimestamp + '.pth.tar')\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            else:\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "                     \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for batchID, (input, target) in enumerate (dataLoader):\n",
    "                        \n",
    "            target = target.cuda()\n",
    "                 \n",
    "            varInput = torch.autograd.Variable(input)\n",
    "            varTarget = torch.autograd.Variable(target)         \n",
    "            varOutput = model(varInput)\n",
    "            \n",
    "            lossvalue = loss(varOutput, varTarget)\n",
    "                       \n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    #-------------------------------------------------------------------------------- \n",
    "        \n",
    "    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n",
    "        \n",
    "        model.eval ()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        \n",
    "        losstensorMean = 0\n",
    "        \n",
    "        for i, (input, target) in enumerate (dataLoader):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            \n",
    "            varInput = torch.autograd.Variable(input, volatile=True)\n",
    "            varTarget = torch.autograd.Variable(target, volatile=True)    \n",
    "            varOutput = model(varInput)\n",
    "            \n",
    "            losstensor = loss(varOutput, varTarget)\n",
    "            losstensorMean += losstensor\n",
    "            \n",
    "            lossVal += losstensor.data[0]\n",
    "            lossValNorm += 1\n",
    "            \n",
    "        outLoss = lossVal / lossValNorm\n",
    "        losstensorMean = losstensorMean / lossValNorm\n",
    "        \n",
    "        return outLoss, losstensorMean\n",
    "               \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            \n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------------  \n",
    "    \n",
    "    #---- Test the trained network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "#     def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n",
    "        \n",
    "        \n",
    "#         CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "#                 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "#         cudnn.benchmark = True\n",
    "        \n",
    "#         #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n",
    "#         model = DenseNet121_Sigmoid(nnClassCount, nnIsTrained).cuda()\n",
    "#         if nnArchitecture == 'DENSE-NET-121-Sigmoid': model = DenseNet121_Sigmoid(nnClassCount, nnIsTrained).cuda()\n",
    "#         elif nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "#         elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "#         elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "#         model = torch.nn.DataParallel(model).cuda() \n",
    "        \n",
    "#         modelCheckpoint = torch.load(pathModel)\n",
    "#         model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "#         #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "#         normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "#         #-------------------- SETTINGS: DATASET BUILDERS\n",
    "#         transformList = []\n",
    "#         transformList.append(transforms.Resize(transResize))\n",
    "#         transformList.append(transforms.TenCrop(transCrop))\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "#         transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "#         transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "#         datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "#         dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=8, shuffle=False, pin_memory=True)\n",
    "        \n",
    "#         outGT = torch.FloatTensor().cuda()\n",
    "#         outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "#         model.eval()\n",
    "        \n",
    "#         for i, (input, target) in enumerate(dataLoaderTest):\n",
    "            \n",
    "#             target = target.cuda()\n",
    "#             outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "#             bs, n_crops, c, h, w = input.size()\n",
    "            \n",
    "#             varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "            \n",
    "#             out = model(varInput)\n",
    "#             outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "#             outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "#         aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "#         aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "#         print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "#         for i in range (0, len(aurocIndividual)):\n",
    "#             print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'DENSE-NET-121-Sigmoid'\n",
    "nnClassCount = 5\n",
    "trBatchSize = 6\n",
    "trMaxEpoch = 50\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = None\n",
    "\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
