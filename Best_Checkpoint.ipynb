{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import cvxpy as cp\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121, DenseNet169\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from dataset import ChestXrayDataSet\n",
    "from metrics import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 9\n",
    "classCount = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, classes=9, classCount=5):\n",
    "    model.eval()\n",
    "    \n",
    "    outGT = torch.FloatTensor().cuda()\n",
    "    outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(dataLoaderVal):\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input.cuda())\n",
    "            varTarget = torch.autograd.Variable(target)\n",
    "            varOutput = model(varInput)\n",
    "\n",
    "            varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "            varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "            varOutput[:,2] = torch.sigmoid(varOutput[:,2])            \n",
    "\n",
    "            ### VAL Preds for AUROC\n",
    "            bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "            bPRED[:,0] = varOutput[:,0]\n",
    "            bPRED[:,1] = varOutput[:,1]\n",
    "            bPRED[:,2] = varOutput[:,2]\n",
    "\n",
    "            softmax = torch.nn.Softmax()\n",
    "            soft_a = softmax(varOutput[:,3:6]).data\n",
    "            a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "            bPRED[:, 3] = a1/(a0+a1)\n",
    "            soft_b = softmax(varOutput[:,6:9]).data\n",
    "            b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "            bPRED[:, 4] = b1/(b0+b1)\n",
    "\n",
    "            outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            ##block comment was here\n",
    "\n",
    "        aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "        print(\"AUROC val\", aurocMean)\n",
    "        print(\"AUROC individual\", aurocIndividual)\n",
    "        \n",
    "    aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "    accMean = np.array(computeAcc(outGT, outPRED, classCount)).mean()\n",
    "    print(\"Mean accuracy\", accMean)\n",
    "    return aurocIndividual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlin/231NProject/dataset.py:66: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  labels = chex_df.as_matrix(columns=diseases)\n",
      "/home/hanlin/231NProject/dataset.py:69: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  image_names = chex_df.as_matrix(columns=['Path']).flatten()\n"
     ]
    }
   ],
   "source": [
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "DATA_DIR = './data'\n",
    "batchSize = 32\n",
    "\n",
    "transResize = (300, 300)\n",
    "\n",
    "#-------------------- SETTINGS: DATA TRANSFORMS\n",
    "normalize = transforms.Normalize([0.50616586, 0.50616586, 0.50616586], [0.2879059, 0.2879059, 0.2879059]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transResize))\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)    \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "datasetVal =   ChestXrayDataSet(data_dir=DATA_DIR, image_list_file=VAL_IMAGE_LIST, transform=transformSequence)\n",
    "dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=batchSize, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo = []\n",
    "model_dir = 'forward'\n",
    "individuals = []\n",
    "for f in os.listdir(model_dir):\n",
    "    print(f)\n",
    "    model = None\n",
    "    model = DenseNet121(classes, False).cuda()\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    checkpoint = torch.load(os.path.join(model_dir, f))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    del checkpoint\n",
    "    aurocIndividual = evaluate_model(model)\n",
    "    individuals.append(aurocIndividual)\n",
    "    \n",
    "best = np.max(np.vstack(individuals), axis=0)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_zoo(model_zoo, classes=9, classCount=5):\n",
    "    for model in model_zoo:\n",
    "        model.eval()\n",
    "    \n",
    "    outGT = torch.FloatTensor().cuda()\n",
    "    outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(dataLoaderVal):\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input.cuda())\n",
    "            varTarget = torch.autograd.Variable(target)\n",
    "            varOutputs = []\n",
    "            for model in model_zoo:\n",
    "                (32,54)\n",
    "                varOutputs.append(np.expand_dims(model(varInput).cpu().numpy(), axis=0)) \n",
    "            \n",
    "            varOutputs = np.vstack(varOutputs)\n",
    "            varOutput = torch.from_numpy(np.mean(varOutputs, axis=0)) ##bug! mean should come after softmax\n",
    "            varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "            varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "            varOutput[:,2] = torch.sigmoid(varOutput[:,2])            \n",
    "\n",
    "            ### VAL Preds for AUROC\n",
    "            bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "            bPRED[:,0] = varOutput[:,0]\n",
    "            bPRED[:,1] = varOutput[:,1]\n",
    "            bPRED[:,2] = varOutput[:,2]\n",
    "\n",
    "            softmax = torch.nn.Softmax()\n",
    "            soft_a = softmax(varOutput[:,3:6]).data\n",
    "            a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "            bPRED[:, 3] = a1/(a0+a1)\n",
    "            soft_b = softmax(varOutput[:,6:9]).data\n",
    "            b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "            bPRED[:, 4] = b1/(b0+b1)\n",
    "\n",
    "            outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            ##block comment was here\n",
    "\n",
    "        aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "        print(\"AUROC val\", aurocMean)\n",
    "        print(\"AUROC individual\", aurocIndividual)\n",
    "        \n",
    "    aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "    accMean = np.array(computeAcc(outGT, outPRED, classCount)).mean()\n",
    "    print(\"Mean accuracy\", accMean)\n",
    "    return aurocIndividual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo_names = ['m-37050_0.897.pth.tar', 'm-48990_0.879.pth.tar', 'm-46590_0.876.pth.tar', 'm-25110_0.886.pth.tar', 'm-14340_0.891.pth.tar', 'm-22710_0.878.pth.tar']\n",
    "model_dir ='forward'\n",
    "\n",
    "model_zoo = []\n",
    "for model_name in model_zoo_names:\n",
    "    model = None\n",
    "    model = DenseNet121(classes, False).cuda()\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    checkpoint = torch.load(os.path.join(model_dir, model_name))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    del checkpoint\n",
    "    model_zoo.append(model)\n",
    "#metrics = evaluate_model_zoo(model_zoo)\n",
    "\n",
    "\n",
    "# 1st element: best model\n",
    "# 2nd to 6th element: best models on each of our diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute weighted sum ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDirData = './data'\n",
    "pathFileTrain = './data/CheXpert-v1.0-small/train.csv'\n",
    "trBatchSize = 32\n",
    "transResize = (300, 300)\n",
    "transCrop = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.50616586, 0.50616586, 0.50616586], [0.2879059, 0.2879059, 0.2879059]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transResize))\n",
    "transformList.append(transforms.ToTensor())\n",
    "transformList.append(normalize)    \n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "#-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "\n",
    "datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, transform=transformSequence)              \n",
    "dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diseases = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_training_set(model_zoo, num_examples):    \n",
    "\n",
    "    for model in model_zoo:\n",
    "        model.eval()\n",
    "    num_models = len(model_zoo)\n",
    "    \n",
    "    outGT = torch.FloatTensor().cuda()\n",
    "    outPREDs = [torch.FloatTensor().cuda()]*num_models\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(dataLoaderTrain):\n",
    "            #Val code\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input.cuda())\n",
    "            varTarget = torch.autograd.Variable(target)\n",
    "            \n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            for m, model in enumerate(model_zoo):\n",
    "                varOutput = model(varInput)\n",
    "\n",
    "                varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "                varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "                varOutput[:,2] = torch.sigmoid(varOutput[:,2])            \n",
    "\n",
    "\n",
    "                ### VAL Preds for AUROC\n",
    "                bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "                bPRED[:,0] = varOutput[:,0]\n",
    "                bPRED[:,1] = varOutput[:,1]\n",
    "                bPRED[:,2] = varOutput[:,2]\n",
    "                \n",
    "                soft_a = torch.nn.functional.softmax(varOutput[:,3:6], dim=-1).data\n",
    "\n",
    "                a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "                bPRED[:, 3] = a1/(a0+a1)\n",
    "                soft_b = torch.nn.functional.softmax(varOutput[:,6:9], dim=-1).data\n",
    "                b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "                bPRED[:, 4] = b1/(b0+b1)\n",
    "\n",
    "#                 outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "#                 outGT = torch.cat((outGT, target), 0)\n",
    "                \n",
    "                outPREDs[m] = torch.cat((outPREDs[m], bPRED.data), 0)            \n",
    "\n",
    "                ##block comment was here\n",
    "            if i % int(100/trBatchSize) == 0:\n",
    "                print(i*trBatchSize)\n",
    "            if i*trBatchSize >= num_examples:\n",
    "                break\n",
    "    return outPREDs, outGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "96\n",
      "192\n",
      "288\n",
      "384\n",
      "480\n",
      "576\n",
      "672\n",
      "768\n",
      "864\n",
      "960\n",
      "1056\n",
      "1152\n",
      "1248\n",
      "1344\n",
      "1440\n",
      "1536\n",
      "1632\n",
      "1728\n",
      "1824\n",
      "1920\n",
      "2016\n",
      "2112\n",
      "2208\n",
      "2304\n",
      "2400\n",
      "2496\n",
      "2592\n",
      "2688\n",
      "2784\n",
      "2880\n",
      "2976\n",
      "3072\n",
      "3168\n",
      "3264\n",
      "3360\n",
      "3456\n",
      "3552\n",
      "3648\n",
      "3744\n",
      "3840\n",
      "3936\n",
      "4032\n",
      "4128\n",
      "4224\n",
      "4320\n",
      "4416\n",
      "4512\n",
      "4608\n",
      "4704\n",
      "4800\n",
      "4896\n",
      "4992\n",
      "5088\n",
      "5184\n",
      "5280\n",
      "5376\n",
      "5472\n",
      "5568\n",
      "5664\n",
      "5760\n",
      "5856\n",
      "5952\n",
      "6048\n",
      "6144\n",
      "6240\n",
      "6336\n",
      "6432\n",
      "6528\n",
      "6624\n",
      "6720\n",
      "6816\n",
      "6912\n",
      "7008\n",
      "7104\n",
      "7200\n",
      "7296\n",
      "7392\n",
      "7488\n",
      "7584\n",
      "7680\n",
      "7776\n",
      "7872\n",
      "7968\n",
      "8064\n",
      "8160\n",
      "8256\n",
      "8352\n",
      "8448\n",
      "8544\n",
      "8640\n",
      "8736\n",
      "8832\n",
      "8928\n",
      "9024\n",
      "9120\n",
      "9216\n",
      "9312\n",
      "9408\n",
      "9504\n",
      "9600\n",
      "9696\n",
      "9792\n",
      "9888\n",
      "9984\n"
     ]
    }
   ],
   "source": [
    "outPREDs, outGT = get_weights_training_set(model_zoo, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_training_sets(outPREDs, outGT):\n",
    "    training_sets = []\n",
    "    probs = []\n",
    "    for m in range(len(outPREDs)):\n",
    "        probs.append(outPREDs[m].cpu().numpy())\n",
    "    pred_volume = np.stack(probs, axis=2)\n",
    "    labels = outGT.cpu().numpy()\n",
    "    for i in range(num_diseases):\n",
    "        Ai = np.squeeze(pred_volume[:, i, :])\n",
    "        bi = labels[:, i]\n",
    "        clear_rows = np.array(bi!=2)\n",
    "        Ai, bi = [Ai[clear_rows, :], bi[clear_rows]]\n",
    "        training_sets.append([Ai, bi])\n",
    "    return(training_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_sets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a5fc67f9c1c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensemble_training_sets.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_sets' is not defined"
     ]
    }
   ],
   "source": [
    "#np.save('ensemble_training_sets.npy', np.array(training_sets),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = get_weight_training_sets(outPREDs, outGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease_0\n",
      "0.18176330936280885\n",
      "weights\n",
      "[0.91951901 0.01       0.07048099]\n",
      "disease_1\n",
      "0.08029805348829164\n",
      "weights\n",
      "[0.98 0.01 0.01]\n",
      "disease_2\n",
      "0.13417284341555916\n",
      "weights\n",
      "[0.96676433 0.01       0.02323567]\n",
      "disease_3\n",
      "0.06475894606611106\n",
      "weights\n",
      "[0.98 0.01 0.01]\n",
      "disease_4\n",
      "0.11788407239981458\n",
      "weights\n",
      "[0.9605097 0.01      0.0294903]\n",
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "reg_weights = []\n",
    "\n",
    "o = np.ones(len(model_zoo))\n",
    "for i in range(len(training_sets)):\n",
    "    Ai, bi = training_sets[i]\n",
    "    wi = cp.Variable(len(model_zoo))\n",
    "    obj = cp.sum_squares(Ai*wi - bi)/Ai.shape[0]\n",
    "    constraints = [wi >= 0.01, wi*o == 1]\n",
    "    prob = cp.Problem(cp.Minimize(obj), constraints=constraints)\n",
    "    print('disease_{}'.format(i))\n",
    "    print(prob.solve())\n",
    "    print('weights')\n",
    "    print(wi.value) \n",
    "    reg_weights.append(wi.value)\n",
    "reg_weights = np.array(reg_weights).T\n",
    "print(reg_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease_0\n",
      "0.5358695972960016\n",
      "weights\n",
      "[0.96618399 0.01       0.02381601]\n",
      "disease_1\n",
      "0.2902021905595151\n",
      "weights\n",
      "[0.98 0.01 0.01]\n",
      "disease_2\n",
      "0.4147129374477254\n",
      "weights\n",
      "[0.98 0.01 0.01]\n",
      "disease_3\n",
      "0.22015427662275353\n",
      "weights\n",
      "[0.98 0.01 0.01]\n",
      "disease_4\n",
      "0.3723372866345213\n",
      "weights\n",
      "[0.97968452 0.01       0.01031548]\n"
     ]
    }
   ],
   "source": [
    "bce_weights = []\n",
    "\n",
    "o = np.ones(len(model_zoo))\n",
    "for i in range(len(training_sets)):\n",
    "    Ai, bi = training_sets[i]\n",
    "    wi = cp.Variable(len(model_zoo))\n",
    "    preds = Ai*wi\n",
    "    obj = cp.sum(cp.multiply(bi, -cp.log(preds)) + cp.multiply(1-bi, -cp.log(1-preds)))\n",
    "    obj = obj/Ai.shape[0]\n",
    "    constraints = [wi >= 0.01, wi*o == 1]\n",
    "    prob = cp.Problem(cp.Minimize(obj), constraints=constraints)\n",
    "    print('disease_{}'.format(i))\n",
    "    print(prob.solve())\n",
    "    print('weights')\n",
    "    print(wi.value) \n",
    "    bce_weights.append(wi.value)\n",
    "bce_weights = np.array(bce_weights).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5) (1, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_weights = []\n",
    "log_intercepts = []\n",
    "for i in range(len(training_sets)):\n",
    "    Ai, bi = training_sets[i]\n",
    "    l = LogisticRegression()\n",
    "    l.fit(Ai, bi)\n",
    "    log_weights.append(l.coef_[0])\n",
    "    log_intercepts.append(l.intercept_[0])\n",
    "log_weights = np.array(log_weights).T\n",
    "log_intercepts = np.array(log_intercepts).reshape(1, num_diseases)\n",
    "print(log_weights.shape, log_intercepts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_zoo_with_weights(model_zoo, weights, log_reg=False, intercepts=None, classes=9, classCount=5):\n",
    "    for model in model_zoo:\n",
    "        model.eval()\n",
    "    num_models = len(model_zoo)\n",
    "    \n",
    "    outGT = torch.FloatTensor().cuda()\n",
    "    outPREDs = [torch.FloatTensor().cuda()]*num_models\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(dataLoaderVal):\n",
    "            #Val code\n",
    "            target = target.cuda()\n",
    "            varInput = torch.autograd.Variable(input.cuda())\n",
    "            varTarget = torch.autograd.Variable(target)\n",
    "            \n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            for m, model in enumerate(model_zoo):\n",
    "                varOutput = model(varInput)\n",
    "\n",
    "                varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "                varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "                varOutput[:,2] = torch.sigmoid(varOutput[:,2])            \n",
    "\n",
    "\n",
    "                ### VAL Preds for AUROC\n",
    "                bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "                bPRED[:,0] = varOutput[:,0]\n",
    "                bPRED[:,1] = varOutput[:,1]\n",
    "                bPRED[:,2] = varOutput[:,2]\n",
    "                \n",
    "                soft_a = torch.nn.functional.softmax(varOutput[:,3:6], dim=-1).data\n",
    "\n",
    "                a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "                bPRED[:, 3] = a1/(a0+a1)\n",
    "                soft_b = torch.nn.functional.softmax(varOutput[:,6:9], dim=-1).data\n",
    "                b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "                bPRED[:, 4] = b1/(b0+b1)\n",
    "\n",
    "#                 outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "#                 outGT = torch.cat((outGT, target), 0)\n",
    "                \n",
    "                outPREDs[m] = torch.cat((outPREDs[m], bPRED.data), 0) \n",
    "            \n",
    "#         print(outPREDs[0][0,:])\n",
    "#         print(weights)\n",
    "        for j,w in enumerate(weights):\n",
    "            w_tensor = torch.from_numpy(w.reshape(1, num_diseases))\n",
    "            w_tensor = w_tensor.type(torch.FloatTensor).cuda()\n",
    "\n",
    "            #w_tensor = torch.FloatTensor(w_tensor).cuda()\n",
    "            outPREDs[j] = outPREDs[j]*w_tensor\n",
    "            if log_reg:\n",
    "                outPREDs[j] += torch.from_numpy(intercepts).type(torch.FloatTensor).cuda()\n",
    "#         print(outPREDs[0][0,:])\n",
    "        outPRED = sum(outPREDs)\n",
    "        if log_reg:\n",
    "            outPRED = torch.sigmoid(outPRED)\n",
    "            \n",
    "            \n",
    "\n",
    "        aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "        print(\"AUROC val\", aurocMean)\n",
    "        print(\"AUROC individual\", aurocIndividual)\n",
    "        \n",
    "    aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "    aurocMean = np.array(aurocIndividual).mean()\n",
    "    accMean = np.array(computeAcc(outGT, outPRED, classCount)).mean()\n",
    "    print(\"Mean accuracy\", accMean)\n",
    "    return aurocIndividual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val 0.9006227811204777\n",
      "AUROC individual [0.8623622047244094, 0.909375, 0.9361607142857142, 0.8656417112299465, 0.9295742753623188]\n",
      "Mean accuracy 0.8158415841584159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8623622047244094,\n",
       " 0.909375,\n",
       " 0.9361607142857142,\n",
       " 0.8656417112299465,\n",
       " 0.9295742753623188]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_zoo_with_weights(model_zoo, reg_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val 0.8970193131756142\n",
      "AUROC individual [0.8619422572178478, 0.9034926470588235, 0.9266369047619047, 0.8680926916221035, 0.9249320652173914]\n",
      "Mean accuracy 0.8069306930693069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8619422572178478,\n",
       " 0.9034926470588235,\n",
       " 0.9266369047619047,\n",
       " 0.8680926916221035,\n",
       " 0.9249320652173914]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_zoo_with_weights(model_zoo, bce_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val 0.8979755296223871\n",
      "AUROC individual [0.8616272965879266, 0.9056985294117648, 0.9342261904761904, 0.8646390374331551, 0.9236865942028986]\n",
      "Mean accuracy 0.7237623762376237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8616272965879266,\n",
       " 0.9056985294117648,\n",
       " 0.9342261904761904,\n",
       " 0.8646390374331551,\n",
       " 0.9236865942028986]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_zoo_with_weights(model_zoo, log_weights, log_reg=True, intercepts=log_intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_zoo2\n",
    "#evaluate_model_zoo_with_weights(model_zoo, np.array([[1/6]*5]*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir ='forward'\n",
    "\n",
    "model_zoo2 = []\n",
    "model = None\n",
    "model = DenseNet121(classes, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('best_models/forward121/m-37050_0-Copy1.897.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "del checkpoint\n",
    "model_zoo2.append(model)\n",
    "\n",
    "model = None\n",
    "model = DenseNet121(classes, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('forward/m-8370_0.893.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "del checkpoint\n",
    "model_zoo2.append(model)\n",
    "\n",
    "# model = None\n",
    "# model = DenseNet121(classes, False).cuda()\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# checkpoint = torch.load('best_models/forward121/m-14340_0-Copy1.891.pth.tar')\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# del checkpoint\n",
    "# model_zoo2.append(model)\n",
    "\n",
    "model = None\n",
    "model = DenseNet169(classes, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('best_models/forward169/m-26280_0.892.pth.tar')\n",
    "checkpoint['state_dict']['module.densenet169.classifier.0.weight'] = checkpoint['state_dict']['module.densenet169.classifier.weight']\n",
    "checkpoint['state_dict']['module.densenet169.classifier.0.bias'] = checkpoint['state_dict']['module.densenet169.classifier.bias']\n",
    "checkpoint['state_dict'].pop('module.densenet169.classifier.weight', None)\n",
    "checkpoint['state_dict'].pop('module.densenet169.classifier.bias', None)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "del checkpoint\n",
    "model_zoo2.append(model)\n",
    "\n",
    "### auroc val 0.9029 without the following model:\n",
    "model = None\n",
    "model = DenseNet169(classes, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('best_models/forward169/m-8370_0.887.pth.tar')\n",
    "checkpoint['state_dict']['module.densenet169.classifier.0.weight'] = checkpoint['state_dict']['module.densenet169.classifier.weight']\n",
    "checkpoint['state_dict']['module.densenet169.classifier.0.bias'] = checkpoint['state_dict']['module.densenet169.classifier.bias']\n",
    "checkpoint['state_dict'].pop('module.densenet169.classifier.weight', None)\n",
    "checkpoint['state_dict'].pop('module.densenet169.classifier.bias', None)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "del checkpoint\n",
    "model_zoo2.append(model)\n",
    "###\n",
    "model_zoo = model_zoo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC val 0.9048359991969152\n",
      "AUROC individual [0.8608923884514437, 0.9069852941176471, 0.9395833333333333, 0.8801247771836007, 0.9365942028985508]\n",
      "Mean accuracy 0.8198019801980199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8608923884514437,\n",
       " 0.9069852941176471,\n",
       " 0.9395833333333333,\n",
       " 0.8801247771836007,\n",
       " 0.9365942028985508]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_zoo_with_weights(model_zoo2, np.array([[1/4]*5]*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
