{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read images and corresponding labels.\n",
    "\"\"\"\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    def __init__(self, data_dir, image_list_file, diseases, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        chex_df = pd.read_csv(image_list_file)\n",
    "        chex_df = chex_df.fillna(0.0)\n",
    "        if 'train' in image_list_file:\n",
    "            chex_df = chex_df[:10000]\n",
    "        if len(diseases) == 1:\n",
    "            chex_df = chex_df.loc[chex_df['Pleural Effusion'] != -1] #U-Ignore\n",
    "            \n",
    "        labels = chex_df.as_matrix(columns=diseases)\n",
    "        labels = list(labels)\n",
    "\n",
    "        image_names = chex_df.as_matrix(columns=['Path']).flatten()\n",
    "        image_names = [os.path.join(data_dir, im_name) for im_name in image_names]\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(1, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('m-.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(1, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "checkpoint = torch.load('m-dense.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "DATA_DIR = './data'\n",
    "trBatchSize = 2\n",
    "transResize = 256\n",
    "transCrop = 224\n",
    "\n",
    "#-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "#-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(transResize))\n",
    "transformList.append(transforms.TenCrop(transCrop))\n",
    "transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "transformSequence=transforms.Compose(transformList)\n",
    "\n",
    "datasetVal =   ChestXrayDataSet(data_dir=DATA_DIR, image_list_file=VAL_IMAGE_LIST, diseases=['Pleural Effusion'], transform=transformSequence)\n",
    "dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAUROC (dataGT, dataPRED, classCount):\n",
    "\n",
    "    outAUROC = []\n",
    "\n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "    for i in range(classCount):\n",
    "        outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "\n",
    "    return outAUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeClassMetrics(dataGT, dataPRED, classCount):\n",
    "    classification_metrics = []\n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "    for i in range(classCount):\n",
    "        pred_to_category = datanpPRED[:, i].copy()\n",
    "        pred_to_category[pred_to_category < 0.5]  = 0\n",
    "        pred_to_category[pred_to_category != 0]  = 1\n",
    "        classification_metrics.append(classification_report(datanpGT[:, i], pred_to_category))\n",
    "    return classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcc(dataGT, dataPRED, classCount):\n",
    "    acc = []\n",
    "    datanpGT = dataGT.cpu().numpy()\n",
    "    datanpPRED = dataPRED.cpu().numpy()\n",
    "\n",
    "    for i in range(classCount):\n",
    "        pred_to_category = datanpPRED[:, i].copy()\n",
    "        pred_to_category[pred_to_category < 0.5]  = 0\n",
    "        pred_to_category[pred_to_category != 0]  = 1\n",
    "        acc.append(accuracy_score(datanpGT[:, i], pred_to_category))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0.09878731 0.03087339 0.03040134 0.4432914  0.01663688 0.57143307\n",
      " 0.42132092 0.03934598 0.03840555 0.08081787 0.8180542  0.02709676\n",
      " 0.02591118 0.11609687 0.00828594 0.84540147 0.0299581  0.03556917\n",
      " 0.4658061  0.02118432 0.01321094 0.08392068 0.06361598 0.05721939\n",
      " 0.07336508 0.03500856 0.12385924 0.3335356  0.01597897 0.0288763\n",
      " 0.07479968 0.1383216  0.0928959  0.04682042 0.02871627 0.03224165\n",
      " 0.04018697 0.02124488 0.3987015  0.07421521 0.03668586 0.22924738\n",
      " 0.01554822 0.27214772 0.03855833 0.03793203 0.01727592 0.02748867\n",
      " 0.68253803 0.32676074 0.1654848  0.9196682  0.08633345 0.06664909\n",
      " 0.03706367 0.60320234 0.49453828 0.03509523 0.03960158 0.18048155\n",
      " 0.12468042 0.07604784 0.03363863 0.01320807 0.05362287 0.04214082\n",
      " 0.08717598 0.04599692 0.03139235 0.28071076 0.07099986 0.03166004\n",
      " 0.05263577 0.06685035 0.05507458 0.11132406 0.04517322 0.02906385\n",
      " 0.34255478 0.07254999 0.07807211 0.16005252 0.07886538 0.08046403\n",
      " 0.0727592  0.75581586 0.53172797 0.1241796  0.03385063 0.11226387\n",
      " 0.05299554 0.57017183 0.80058795 0.48194596 0.22779897 0.09054353\n",
      " 0.15248811 0.31601924 0.05476615 0.06619945 0.02623372 0.03622809\n",
      " 0.18329044 0.09343942 0.04517416 0.03027345 0.07130361 0.01219873\n",
      " 0.50139546 0.8363496  0.04991256 0.47720748 0.8991246  0.29493713\n",
      " 0.03871381 0.15543862 0.02838411 0.01088732 0.02111886 0.04029226\n",
      " 0.81214124 0.09239113 0.29507756 0.80675316 0.4593897  0.15155378\n",
      " 0.11852311 0.16477345 0.02879766 0.8573393  0.35231826 0.70358706\n",
      " 0.46356955 0.3054439  0.74846405 0.6688849  0.8878619  0.10297669\n",
      " 0.02208667 0.05253336 0.65298367 0.8811283  0.04271956 0.54624283\n",
      " 0.26566124 0.1813373  0.53527224 0.7165322  0.8194817  0.22437046\n",
      " 0.83544654 0.76639974 0.20619892 0.03773224 0.3247528  0.29265904\n",
      " 0.5142357  0.17806171 0.5801345  0.45673943 0.611477   0.45524684\n",
      " 0.33013865 0.24505262 0.37615094 0.45603514 0.21975128 0.44190168\n",
      " 0.73052365 0.27369538 0.8234464  0.19166146 0.10202362 0.73831654\n",
      " 0.45928842 0.89251536 0.6628583  0.04122504 0.1548791  0.41030845\n",
      " 0.87812275 0.6463479  0.5268844  0.4099872  0.8731192  0.20635806\n",
      " 0.16340978 0.02902141 0.092985   0.59714776 0.10657537 0.084653\n",
      " 0.218642   0.11077233 0.5351595  0.55969214 0.8580087  0.07711101\n",
      " 0.12896188 0.22731891 0.13520972 0.07456682 0.04005196 0.1029759\n",
      " 0.92397374 0.08419953 0.0935758  0.18480419 0.88194317 0.03171235\n",
      " 0.75709313 0.3434588  0.1536939  0.4691196  0.08800779 0.21754125\n",
      " 0.04621585 0.0156878  0.37375745 0.06633519 0.02800059 0.10860216\n",
      " 0.27605224 0.13325815 0.07191069 0.0141217  0.07855608 0.31418115\n",
      " 0.23583113 0.05030373 0.08338965 0.04174155 0.04178831 0.55651253]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9105371346858522"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outGT = torch.FloatTensor().cuda()\n",
    "outPRED = torch.FloatTensor().cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "lossVal = 0\n",
    "lossValNorm = 0\n",
    "classCount = 1\n",
    "\n",
    "losstensorMean = 0\n",
    "for i, (input, target) in enumerate(dataLoaderVal):\n",
    "\n",
    "    target = target.cuda()\n",
    "    outGT = torch.cat((outGT, target), 0)\n",
    "    loss = torch.nn.BCELoss(size_average = True)\n",
    "\n",
    "    bs, n_crops, c, h, w = input.size()\n",
    "\n",
    "    varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n",
    "\n",
    "    out = model(varInput)\n",
    "    outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "\n",
    "    outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "    varOutput = outPRED\n",
    "    varTarget = outGT\n",
    "\n",
    "    losstensor = loss(varOutput, varTarget)\n",
    "    losstensorMean += losstensor\n",
    "    lossVal += losstensor.item()\n",
    "    lossValNorm += 1\n",
    "\n",
    "outLoss = lossVal / lossValNorm\n",
    "losstensorMean = losstensorMean / lossValNorm\n",
    "\n",
    "classMetrics = computeClassMetrics(outGT, outPRED, classCount)\n",
    "aurocIndividual = computeAUROC(outGT, outPRED, classCount)\n",
    "aurocMean = np.array(aurocIndividual).mean()\n",
    "accMean = np.array(computeAcc(outGT, outPRED, classCount)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.9105371346858522\n"
     ]
    }
   ],
   "source": [
    "print('AUROC:', aurocMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90       167\n",
      "         1.0       0.83      0.60      0.70        67\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       234\n",
      "   macro avg       0.84      0.77      0.80       234\n",
      "weighted avg       0.85      0.85      0.84       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in classMetrics:\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8504273504273504\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
