{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4e7998386cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseNet121\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnClassCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodelCheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelCheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "nnClassCount = 9\n",
    "model = DenseNet121(nnClassCount, False).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "modelCheckpoint = torch.load(checkpoint)\n",
    "model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "optimizer.load_state_dict(modelCheckpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class forward_side(nn.Module):\n",
    "    def __init__(self, nnClassCount, forward_cp, side_cp):\n",
    "        super(forward_side, self).__init__()\n",
    "        self.forwardModel = DenseNet121(nnClassCount, False)\n",
    "        self.sideModel = DenseNet121(nnClassCount, False)\n",
    "        \n",
    "        Fstate_dict = self.change_state_dict_keys(torch.load(forward_cp)['state_dict'])\n",
    "        Cstate_dict = self.change_state_dict_keys(torch.load(side_cp)['state_dict'])\n",
    "        self.forwardModel.load_state_dict(Fstate_dict)\n",
    "        self.sideModel.load_state_dict(Cstate_dict)\n",
    "        \n",
    "#         for i, param in enumerate(self.forwardModel.parameters()):\n",
    "#             if i < len(list(self.forwardModel.parameters())) - 5:\n",
    "#                 param.requires_grad = False\n",
    "#         for i, param in enumerate(self.sideModel.parameters()):\n",
    "#             if i < len(list(self.sideModel.parameters())) - 5:\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "        for param in self.forwardModel.parameters():\n",
    "            param.requires_grad = False\n",
    "#         for param in self.sideModel.parameters():\n",
    "#             param.requires_grad = False\n",
    "            \n",
    "# #         for param in self.sideModel.features.denseblock1.denselayer1.parameters():\n",
    "# #             param.requires_grad = False\n",
    "#         print([k for k in self.sideModel.children()])  \n",
    "#         l = list([[[v for v in w.children()] for w in c.children()] for c in self.sideModel.children()])\n",
    "# #         print(l[0][0][-2])\n",
    "#         last_dense_block = l[0][0][-2]\n",
    "#         for param in last_dense_block.parameters():\n",
    "#             param.requires_grad = True\n",
    "# #         print(l)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.FkernelCount = self.forwardModel.densenet121.classifier.in_features\n",
    "        self.SkernelCount = self.sideModel.densenet121.classifier.in_features\n",
    "        self.forwardModel.densenet121.classifier = nn.Identity()\n",
    "        self.sideModel.densenet121.classifier = nn.Identity()\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.FkernelCount+self.SkernelCount,500)\n",
    "        self.fc2 = nn.Linear(500,100)\n",
    "        self.fc3 = nn.Linear(100,nnClassCount)\n",
    "        \n",
    "    def change_state_dict_keys(self,state_dict):\n",
    "        keys = state_dict.keys()\n",
    "        new_state_dict = {}\n",
    "        for key in keys:\n",
    "            clean_k = '.'.join(key.split('.')[1:]) # module.dense121.conv0.weight -> dense121.conv0.weight\n",
    "            new_state_dict[clean_k] = state_dict[key]\n",
    "        return new_state_dict\n",
    "        \n",
    "    def forward(self, xF,xS):\n",
    "        xF = self.forwardModel(xF)\n",
    "        xS = self.sideModel(xS)\n",
    "        x = torch.cat((xF,xS),-1)\n",
    "        x = func.relu(self.fc1(x))\n",
    "        x = func.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcheckpoint = './best_models/forward121/m-37050_0-Copy1.897.pth.tar'\n",
    "Scheckpoint = './best_models/lateral/m-9117_0.882.pth.tar'\n",
    "nnClassCount = 9\n",
    "model = forward_side(nnClassCount,Fcheckpoint,Scheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:99: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoc val\n",
      "AUROC val 0.38200098875293537\n",
      "AUROC all [0.4222222222222223, 0.935483870967742, 0.04597701149425289, 0.14999999999999997, 0.3563218390804598]\n",
      "Val loss 0.8774210214614868\n",
      "Loss:0.87368243932724\n",
      "epoc val\n",
      "AUROC val 0.38200098875293537\n",
      "AUROC all [0.4222222222222223, 0.935483870967742, 0.04597701149425289, 0.14999999999999997, 0.3563218390804598]\n",
      "Val loss 0.8774210214614868\n",
      "epoc val\n",
      "AUROC val 0.8848914431673054\n",
      "AUROC all [0.8296296296296297, 1.0, 0.8505747126436782, 0.9166666666666667, 0.8275862068965517]\n",
      "Val loss 0.2696983516216278\n",
      "Loss:0.5560786724090576\n",
      "epoc val\n",
      "AUROC val 0.8848914431673054\n",
      "AUROC all [0.8296296296296297, 1.0, 0.8505747126436782, 0.9166666666666667, 0.8275862068965517]\n",
      "Val loss 0.2696983516216278\n",
      "epoc val\n",
      "AUROC val 0.8611494252873563\n",
      "AUROC all [0.8666666666666667, 1.0, 0.7931034482758621, 0.9333333333333333, 0.7126436781609196]\n",
      "Val loss 0.25209665298461914\n",
      "Loss:0.49939316511154175\n",
      "epoc val\n",
      "AUROC val 0.8611494252873563\n",
      "AUROC all [0.8666666666666667, 1.0, 0.7931034482758621, 0.9333333333333333, 0.7126436781609196]\n",
      "Val loss 0.25209665298461914\n",
      "epoc val\n",
      "AUROC val 0.8756960408684547\n",
      "AUROC all [0.8962962962962963, 1.0, 0.8620689655172414, 0.85, 0.7701149425287357]\n",
      "Val loss 0.24021947383880615\n",
      "Loss:0.4694226384162903\n",
      "epoc val\n",
      "AUROC val 0.8756960408684547\n",
      "AUROC all [0.8962962962962963, 1.0, 0.8620689655172414, 0.85, 0.7701149425287357]\n",
      "Val loss 0.24021947383880615\n",
      "epoc val\n",
      "AUROC val 0.8569604086845466\n",
      "AUROC all [0.8296296296296296, 1.0, 0.8620689655172413, 0.8, 0.7931034482758621]\n",
      "Val loss 0.25767311453819275\n",
      "Loss:0.4546629786491394\n",
      "epoc val\n",
      "AUROC val 0.8569604086845466\n",
      "AUROC all [0.8296296296296296, 1.0, 0.8620689655172413, 0.8, 0.7931034482758621]\n",
      "Val loss 0.25767311453819275\n",
      "epoc val\n",
      "AUROC val 0.885338441890166\n",
      "AUROC all [0.837037037037037, 1.0, 0.9195402298850575, 0.9, 0.7701149425287356]\n",
      "Val loss 0.262153297662735\n",
      "Loss:0.4432114064693451\n",
      "epoc val\n",
      "AUROC val 0.885338441890166\n",
      "AUROC all [0.837037037037037, 1.0, 0.9195402298850575, 0.9, 0.7701149425287356]\n",
      "Val loss 0.262153297662735\n",
      "epoc val\n",
      "AUROC val 0.8955555555555555\n",
      "AUROC all [0.8444444444444446, 1.0, 0.8505747126436782, 0.9666666666666667, 0.8160919540229884]\n",
      "Val loss 0.24225015938282013\n",
      "Loss:0.43843960762023926\n",
      "epoc val\n",
      "AUROC val 0.8955555555555555\n",
      "AUROC all [0.8444444444444446, 1.0, 0.8505747126436782, 0.9666666666666667, 0.8160919540229884]\n",
      "Val loss 0.24225015938282013\n",
      "epoc val\n",
      "AUROC val 0.8926819923371647\n",
      "AUROC all [0.8444444444444446, 1.0, 0.8850574712643678, 0.8833333333333334, 0.8505747126436781]\n",
      "Val loss 0.24473631381988525\n",
      "Loss:0.4318164587020874\n",
      "epoc val\n",
      "AUROC val 0.8926819923371647\n",
      "AUROC all [0.8444444444444446, 1.0, 0.8850574712643678, 0.8833333333333334, 0.8505747126436781]\n",
      "Val loss 0.24473631381988525\n",
      "epoc val\n",
      "AUROC val 0.9117369093231161\n",
      "AUROC all [0.7925925925925926, 1.0, 0.9310344827586207, 0.9500000000000001, 0.8850574712643677]\n",
      "Val loss 0.2499854862689972\n",
      "Loss:0.42993587255477905\n",
      "epoc val\n",
      "AUROC val 0.9117369093231161\n",
      "AUROC all [0.7925925925925926, 1.0, 0.9310344827586207, 0.9500000000000001, 0.8850574712643677]\n",
      "Val loss 0.2499854862689972\n",
      "epoc val\n",
      "AUROC val 0.9239719029374202\n",
      "AUROC all [0.8296296296296297, 1.0, 0.9655172413793104, 0.9166666666666667, 0.9080459770114943]\n",
      "Val loss 0.238856241106987\n",
      "Loss:0.42655009031295776\n",
      "epoc val\n",
      "AUROC val 0.9239719029374202\n",
      "AUROC all [0.8296296296296297, 1.0, 0.9655172413793104, 0.9166666666666667, 0.9080459770114943]\n",
      "Val loss 0.238856241106987\n",
      "epoc val\n",
      "AUROC val 0.9230012771392083\n",
      "AUROC all [0.8592592592592593, 1.0, 0.9425287356321839, 0.9166666666666667, 0.896551724137931]\n",
      "Val loss 0.23023740947246552\n",
      "Loss:0.42383792996406555\n",
      "epoc val\n",
      "AUROC val 0.9230012771392083\n",
      "AUROC all [0.8592592592592593, 1.0, 0.9425287356321839, 0.9166666666666667, 0.896551724137931]\n",
      "Val loss 0.23023740947246552\n",
      "epoc val\n",
      "AUROC val 0.9087739463601533\n",
      "AUROC all [0.7777777777777779, 1.0, 0.9195402298850575, 0.9500000000000001, 0.896551724137931]\n",
      "Val loss 0.24174277484416962\n",
      "Loss:0.4215530753135681\n",
      "epoc val\n",
      "AUROC val 0.9087739463601533\n",
      "AUROC all [0.7777777777777779, 1.0, 0.9195402298850575, 0.9500000000000001, 0.896551724137931]\n",
      "Val loss 0.24174277484416962\n",
      "epoc val\n",
      "AUROC val 0.9149297573435504\n",
      "AUROC all [0.8074074074074075, 1.0, 0.9310344827586207, 0.9166666666666667, 0.9195402298850575]\n",
      "Val loss 0.25580477714538574\n",
      "Loss:0.4203779399394989\n",
      "epoc val\n",
      "AUROC val 0.9149297573435504\n",
      "AUROC all [0.8074074074074075, 1.0, 0.9310344827586207, 0.9166666666666667, 0.9195402298850575]\n",
      "Val loss 0.25580477714538574\n",
      "epoc val\n",
      "AUROC val 0.9239719029374202\n",
      "AUROC all [0.8296296296296297, 1.0, 0.9540229885057471, 0.9166666666666667, 0.9195402298850575]\n",
      "Val loss 0.21973709762096405\n",
      "Loss:0.4200138449668884\n",
      "epoc val\n",
      "AUROC val 0.9239719029374202\n",
      "AUROC all [0.8296296296296297, 1.0, 0.9540229885057471, 0.9166666666666667, 0.9195402298850575]\n",
      "Val loss 0.21973709762096405\n",
      "epoc val\n",
      "AUROC val 0.9324904214559387\n",
      "AUROC all [0.8222222222222222, 1.0, 0.9310344827586207, 0.9666666666666667, 0.9425287356321839]\n",
      "Val loss 0.21887031197547913\n",
      "Loss:0.4193676710128784\n",
      "epoc val\n",
      "AUROC val 0.9324904214559387\n",
      "AUROC all [0.8222222222222222, 1.0, 0.9310344827586207, 0.9666666666666667, 0.9425287356321839]\n",
      "Val loss 0.21887031197547913\n",
      "epoc val\n",
      "AUROC val 0.9369348659003831\n",
      "AUROC all [0.8444444444444444, 1.0, 0.9540229885057471, 0.9666666666666667, 0.9195402298850575]\n",
      "Val loss 0.2474544793367386\n",
      "Loss:0.4171186089515686\n",
      "epoc val\n",
      "AUROC val 0.9369348659003831\n",
      "AUROC all [0.8444444444444444, 1.0, 0.9540229885057471, 0.9666666666666667, 0.9195402298850575]\n",
      "Val loss 0.2474544793367386\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as tfunc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as func\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from models.chexnet.DensenetModels import DenseNet121\n",
    "from models.models import ResNet18\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "writer = SummaryWriter('./logs')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Read images and corresponding labels.\n",
    "\"\"\"\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    \n",
    "    def convert_to_ones(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 1.0)\n",
    "    \n",
    "    def convert_to_zeros(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 0.0)\n",
    "        \n",
    "    def convert_to_multi(self, df, disease):\n",
    "        df[disease] = df[disease].replace([-1.0], 2.0)\n",
    "\n",
    "    def __init__(self, data_dir, image_list_file, diseases=['Atelectasis', 'Consolidation', 'Edema','Cardiomegaly', 'Pleural Effusion'], side='Frontal', frontTransform=None, sideTransform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        chex_df = pd.read_csv(image_list_file)\n",
    "        chex_df = chex_df.fillna(0.0)\n",
    "#         if side == 'Hybrid':\n",
    "#             good_lat_indices = []\n",
    "#             paths = chex_df['Path']\n",
    "#             for i in range(1, len(paths)):\n",
    "#                 path_lat = paths[i]\n",
    "#                 if 'lateral' in path_lat:\n",
    "#                     if path_lat.replace('2_lateral', '1_frontal') in paths[i-1]:\n",
    "#                         good_lat_indices.append(i)\n",
    "#             chex_df = chex_df.iloc[good_lat_indices, :]  \n",
    "#         else:\n",
    "#            chex_df = chex_df.loc[chex_df['Frontal/Lateral'] == 'Lateral']\n",
    "    \n",
    "        if side == 'Hybrid':\n",
    "            good_lat_indices = []\n",
    "            paths = chex_df['Path']\n",
    "            for i in range(1, len(paths)):\n",
    "                path_lat = paths[i]\n",
    "                if 'lateral' in path_lat:\n",
    "                    if os.path.isfile('./data/' + path_lat.replace('2_lateral', '1_frontal')):\n",
    "                        good_lat_indices.append(i)\n",
    "            chex_df = chex_df.iloc[good_lat_indices, :] \n",
    "        else:\n",
    "            chex_df = chex_df.loc[chex_df['Frontal/Lateral'] == side]\n",
    "        self.convert_to_ones(chex_df, 'Atelectasis')\n",
    "        self.convert_to_ones(chex_df, 'Consolidation')\n",
    "        self.convert_to_ones(chex_df, 'Edema')\n",
    "        self.convert_to_multi(chex_df, 'Cardiomegaly')\n",
    "        self.convert_to_multi(chex_df, 'Pleural Effusion')\n",
    "\n",
    "#         chex_df_diseases = chex_df[diseases]\n",
    "                         \n",
    "#         if 'train' in image_list_file:\n",
    "#             chex_df = chex_df\n",
    "#         if len(diseases) == 1:\n",
    "#             chex_df = chex_df.loc[chex_df['Pleural Effusion'] != -1] #U-Ignore\n",
    "#         print(chex_df)\n",
    "        labels = chex_df.as_matrix(columns=diseases)\n",
    "        labels = list(labels)\n",
    "\n",
    "        image_names = chex_df.as_matrix(columns=['Path']).flatten()\n",
    "        image_names = [os.path.join(data_dir, im_name) for im_name in image_names]\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.frontTransform = frontTransform\n",
    "        self.sideTransform = sideTransform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        side_image_name = self.image_names[index]\n",
    "        front_image_name = side_image_name.replace('2_lateral', '1_frontal')\n",
    "        side_image = Image.open(side_image_name).convert('RGB')\n",
    "        front_image = Image.open(front_image_name).convert('RGB')\n",
    "        label = torch.FloatTensor(self.labels[index])\n",
    "        #if self.transform is not None:\n",
    "        side_image = self.sideTransform(side_image)\n",
    "        front_image = self.frontTransform(front_image)\n",
    "        return front_image, side_image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class ChexnetTrainer():\n",
    "\n",
    "    #---- Train the densenet network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    #--- classes - is the number of classes to predict (Note =/= final layer of Dense Net) -- Saj\n",
    "    \n",
    "    \n",
    "    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint,classes):\n",
    "        #------------------  Special Loss \n",
    "        # Takes in Logits, except 0,1,2 --> logits => sigmoid\n",
    "        # returns multi label loss\n",
    "        def lossCriterion(varOutput,varTarget):\n",
    "            CEloss =  torch.nn.CrossEntropyLoss()\n",
    "            BCEloss = torch.nn.BCELoss()\n",
    "\n",
    "            L1 = BCEloss(varOutput[:,0],varTarget[:,0]) \n",
    "            L2 = BCEloss(varOutput[:,1],varTarget[:,1])\n",
    "            L3 = BCEloss(varOutput[:,2],varTarget[:,2])\n",
    "            varTarget = varTarget.long()\n",
    "            L4 = CEloss(varOutput[:,3:6],varTarget[:,3])\n",
    "            L5 = CEloss(varOutput[:,6:9],varTarget[:,4])\n",
    "\n",
    "            \n",
    "            lossvalue = (L1 + L2 + L3 + L4 + L5)/5\n",
    "            \n",
    "            return lossvalue\n",
    "        \n",
    "        #--------------------Settings: best models for side-forward\n",
    "        Fcheckpoint = './best_models/forward121/m-14340_0-Copy1.891.pth.tar'\n",
    "        Scheckpoint = './best_models/lateral/m-5065_0.874.pth.tar'\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'RES-NET-18': model = ResNet18(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'side-forward': model = forward_side(nnClassCount,Fcheckpoint,Scheckpoint)\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "       \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS |TRAIN|\n",
    "        normalize = transforms.Normalize([0.50616586, 0.50616586, 0.50616586], [0.2879059, 0.2879059, 0.2879059]) #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)    \n",
    "        \n",
    "        transforms.RandomApply([\n",
    "                transforms.RandomChoice([\n",
    "                                    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "                                     transforms.RandomAffine(180, translate=(0.2, 0.2), scale=(0.8,1.2), shear=20, resample=False, fillcolor=0),\n",
    "                                     transforms.RandomHorizontalFlip(p=0.3)\n",
    "                                    ]),\n",
    "                                     #transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)]\n",
    "                                   \n",
    "            transforms.RandomChoice(\n",
    "                [transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "                                     transforms.RandomAffine(180, translate=(0.2, 0.2), scale=(0.8,1.2), shear=20, resample=False, fillcolor=0),\n",
    "                                     transforms.RandomHorizontalFlip(p=0.3)]\n",
    "                                     #transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)]\n",
    "                                   ) ]\n",
    "        )\n",
    "        sideTransformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.ToTensor())\n",
    "        transformList.append(normalize)    \n",
    "        valTransformSequence=transforms.Compose(transformList) #normal transforms, augment side views\n",
    "\n",
    "        #-------------------- SETTINGS: DATASET BUILDER |TRAIN|\n",
    "                    \n",
    "        datasetTrain = ChestXrayDataSet(data_dir=pathDirData,image_list_file=pathFileTrain, side='Hybrid', frontTransform=valTransformSequence, sideTransform=sideTransformSequence)              \n",
    "        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS |VAL|\n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS |VAL|\n",
    "        datasetVal =   ChestXrayDataSet(data_dir=pathDirData, image_list_file=pathFileVal, side='Hybrid', frontTransform=valTransformSequence, sideTransform=valTransformSequence)\n",
    "        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, shuffle=False, num_workers=0, pin_memory=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n",
    "        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n",
    "\n",
    "        #-------------------- SETTINGS: LOSS\n",
    "        loss = lossCriterion\n",
    "       \n",
    "        counter = 0\n",
    "        \n",
    "\t#---- Load checkpoint \n",
    "        if checkpoint != None:\n",
    "            modelCheckpoint = torch.load(checkpoint)\n",
    "            model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n",
    "            counter = modelCheckpoint['counter']\n",
    "        \n",
    "        #---- TRAIN THE NETWORK\n",
    "        lossMIN = 100000\n",
    "        \n",
    "        for epochID in range (0, trMaxEpoch):\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampSTART = timestampDate + '-' + timestampTime\n",
    "                         \n",
    "            lossTrain, counter = ChexnetTrainer.epochTrain (model, dataLoaderTrain, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter,classes)\n",
    "            lossVal, losstensor, __ = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, trMaxEpoch, nnClassCount, loss, counter,classes)\n",
    "            \n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + '-' + timestampTime\n",
    "\n",
    "            scheduler.step(losstensor.item())\n",
    "            writer.add_scalar('logs/train_loss_epoch', lossTrain, epochID)\n",
    "            writer.add_scalar('logs/val_loss_epoch', lossVal, epochID)\n",
    "            if lossVal < lossMIN:\n",
    "\n",
    "                lossMIN = lossVal    \n",
    "                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, './hybrid_aug/m-' + launchTimestamp + '.pth.tar')\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "            else:\n",
    "                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n",
    "                     \n",
    "    #-------------------------------------------------------------------------------- \n",
    "       \n",
    "    def epochTrain (model, dataLoader, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes):\n",
    "        \n",
    "        model.train()\n",
    "        lossTrain = 0\n",
    "        lossTrainNorm = 0\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for batchID, (input1, input2, target) in enumerate (dataLoader):\n",
    "\n",
    "            target = target.cuda()\n",
    "            varInput1 = torch.autograd.Variable(input1)\n",
    "            varInput2 = torch.autograd.Variable(input2)\n",
    "            varTarget = torch.autograd.Variable(target)         \n",
    "            varOutput = model(varInput1,varInput2)\n",
    "\n",
    "\n",
    "            varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "            varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "            varOutput[:,2] = torch.sigmoid(varOutput[:,2])\n",
    "\n",
    "            lossvalue = loss(varOutput,varTarget)\n",
    "\n",
    "            avg_loss = avg_loss * (batchID)/(batchID+1) + lossvalue * 1.0/(batchID+ 1)\n",
    "            lossTrain += lossvalue\n",
    "            lossTrainNorm += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            lossvalue.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('logs/train_loss', avg_loss, counter)\n",
    "            if batchID % 41 == 0:\n",
    "                ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes)\n",
    "                print('Loss:' + str(avg_loss.item()))\n",
    "            if batchID % 41 == 0:\n",
    "                __, __, aurocMean = ChexnetTrainer.epochVal(model, dataLoaderVal, optimizer, scheduler, epochMax, classCount, loss, counter,classes)\n",
    "                torch.save({'counter' : counter, 'state_dict': model.state_dict(), 'valAUROC' : aurocMean , 'optimizer' : optimizer.state_dict()}, './hybrid_aug/m-' + str(counter) + '_' + str(round(aurocMean, 3)) + '.pth.tar')\n",
    "\n",
    "                \n",
    "#             print(counter)\n",
    "            counter += 1\n",
    "\n",
    "        outLoss = lossTrain/lossTrainNorm\n",
    "        return outLoss, counter\n",
    "\n",
    "                        \n",
    "    #-------------------------------------------------------------------------------- \n",
    "        \n",
    "    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss, counter,classes):\n",
    "        \n",
    "        print('epoc val')\n",
    "        model.eval()\n",
    "        \n",
    "        lossVal = 0\n",
    "        lossValNorm = 0\n",
    "        losstensorMean = 0\n",
    "\n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "        with torch.no_grad():\n",
    "            for i, (input1, input2, target) in enumerate(dataLoader):\n",
    "                #Val code\n",
    "                target = target.cuda()\n",
    "                varInput1 = torch.autograd.Variable(input1).cuda()\n",
    "                varInput2 = torch.autograd.Variable(input2).cuda()\n",
    "                varTarget = torch.autograd.Variable(target)\n",
    "                varOutput = model(varInput1,varInput2)\n",
    "\n",
    "                varOutput[:,0] = torch.sigmoid(varOutput[:,0])\n",
    "                varOutput[:,1] = torch.sigmoid(varOutput[:,1])\n",
    "                varOutput[:,2] = torch.sigmoid(varOutput[:,2])            \n",
    "\n",
    "\n",
    "                ### VAL Preds for AUROC\n",
    "                bPRED = torch.zeros(varOutput.shape[0], 5).cuda()\n",
    "                bPRED[:,0] = varOutput[:,0]\n",
    "                bPRED[:,1] = varOutput[:,1]\n",
    "                bPRED[:,2] = varOutput[:,2]\n",
    "                \n",
    "                soft_a = torch.nn.functional.softmax(varOutput[:,3:6], dim=-1).data\n",
    "\n",
    "                a0, a1, a2 = soft_a[:, 0], soft_a[:, 1], soft_a[:, 2]\n",
    "                bPRED[:, 3] = a1/(a0+a1)\n",
    "                soft_b = torch.nn.functional.softmax(varOutput[:,6:9], dim=-1).data\n",
    "                b0, b1, b2 = soft_b[:, 0], soft_b[:, 1], soft_b[:, 2]\n",
    "                bPRED[:, 4] = b1/(b0+b1)\n",
    "\n",
    "                outPRED = torch.cat((outPRED, bPRED.data), 0)            \n",
    "                outGT = torch.cat((outGT, target), 0)\n",
    "\n",
    "\n",
    "                losstensor = loss(varOutput,varTarget)\n",
    "\n",
    "                losstensorMean += losstensor\n",
    "                lossVal += losstensor.item()\n",
    "                lossValNorm += 1\n",
    "                ##block comment was here\n",
    "\n",
    "            outLoss = lossVal / lossValNorm\n",
    "            losstensorMean = losstensorMean / lossValNorm\n",
    "\n",
    "            aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, classes)\n",
    "            aurocMean = np.array(aurocIndividual).mean()\n",
    "\n",
    "            print(\"AUROC val\", aurocMean)\n",
    "            print(\"AUROC all\", aurocIndividual)\n",
    "            print(\"Val loss\", outLoss)\n",
    "            writer.add_scalar('logs/val_auroc', aurocMean, counter)\n",
    "\n",
    "        return outLoss, losstensorMean, aurocMean            \n",
    "\n",
    "\n",
    "               \n",
    "    #--------------------------------------------------------------------------------     \n",
    "     \n",
    "    #---- Computes area under ROC curve \n",
    "    #---- dataGT - ground truth data\n",
    "    #---- dataPRED - predicted data\n",
    "    #---- classCount - number of classes\n",
    "    \n",
    "    def computeAUROC (dataGT, dataPRED, classCount):\n",
    "        \n",
    "        outAUROC = []\n",
    "        \n",
    "        datanpGT = dataGT.cpu().numpy()\n",
    "        datanpPRED = dataPRED.cpu().numpy()\n",
    "        \n",
    "        for i in range(classCount):\n",
    "            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n",
    "            \n",
    "        return outAUROC\n",
    "        \n",
    "        \n",
    "    #--------------------------------------------------------------------------------  \n",
    "    \n",
    "    #---- Test the trained network \n",
    "    #---- pathDirData - path to the directory that contains images\n",
    "    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n",
    "    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n",
    "    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n",
    "    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n",
    "    #---- nnClassCount - number of output classes \n",
    "    #---- trBatchSize - batch size\n",
    "    #---- trMaxEpoch - number of epochs\n",
    "    #---- transResize - size of the image to scale down to (not used in current implementation)\n",
    "    #---- transCrop - size of the cropped image \n",
    "    #---- launchTimestamp - date/time, used to assign unique name for the checkpoint file\n",
    "    #---- checkpoint - if not None loads the model and continues training\n",
    "    \n",
    "    def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n",
    "        \n",
    "        \n",
    "        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "        \n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n",
    "        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n",
    "        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n",
    "        \n",
    "        model = torch.nn.DataParallel(model).cuda() \n",
    "        \n",
    "        modelCheckpoint = torch.load(pathModel)\n",
    "        model.load_state_dict(modelCheckpoint['state_dict'])\n",
    "\n",
    "        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n",
    "        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        #-------------------- SETTINGS: DATASET BUILDERS\n",
    "        transformList = []\n",
    "        transformList.append(transforms.Resize(transResize))\n",
    "        transformList.append(transforms.TenCrop(transCrop))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n",
    "        transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n",
    "        transformSequence=transforms.Compose(transformList)\n",
    "        \n",
    "        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, pathDatasetFile=pathFileTest, transform=transformSequence)\n",
    "        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize, num_workers=0, shuffle=False, pin_memory=False)\n",
    "        \n",
    "        outGT = torch.FloatTensor().cuda()\n",
    "        outPRED = torch.FloatTensor().cuda()\n",
    "       \n",
    "        model.eval()\n",
    "        \n",
    "        for i, (input, target) in enumerate(dataLoaderTest):\n",
    "            \n",
    "            target = target.cuda()\n",
    "            outGT = torch.cat((outGT, target), 0)\n",
    "            \n",
    "            bs, n_crops, c, h, w = input.size()\n",
    "            \n",
    "            varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda())\n",
    "            \n",
    "            out = model(varInput)\n",
    "            outMean = out.view(bs, n_crops, -1).mean(1)\n",
    "            \n",
    "            outPRED = torch.cat((outPRED, outMean.data), 0)\n",
    "\n",
    "        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n",
    "        aurocMean = np.array(aurocIndividual).mean()\n",
    "        \n",
    "        print ('AUROC mean ', aurocMean)\n",
    "        \n",
    "        for i in range (0, len(aurocIndividual)):\n",
    "            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n",
    "        \n",
    "     \n",
    "        return\n",
    "#-------------------------------------------------------------------------------- \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "DATA_DIR = './data'\n",
    "TRAIN_IMAGE_LIST = './data/CheXpert-v1.0-small/train.csv'\n",
    "VAL_IMAGE_LIST = './data/CheXpert-v1.0-small/valid.csv'\n",
    "valid_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                image_list_file=VAL_IMAGE_LIST)\n",
    "\n",
    "nnIsTrained = True\n",
    "nnArchitecture = 'side-forward'\n",
    "\n",
    "nnClassCount = 9\n",
    "classes = 5\n",
    "\n",
    "trBatchSize = 32\n",
    "trMaxEpoch = 50\n",
    "transResize = (300, 300)\n",
    "transCrop = 224\n",
    "launchTimestamp = ''\n",
    "checkpoint = None\n",
    "ChexnetTrainer.train(DATA_DIR,TRAIN_IMAGE_LIST,VAL_IMAGE_LIST,nnArchitecture, nnIsTrained, nnClassCount, trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint,classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
